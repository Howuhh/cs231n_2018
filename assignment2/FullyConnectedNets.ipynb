{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fully-Connected Neural Nets\n",
    "In the previous homework you implemented a fully-connected two-layer neural network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as we move to bigger models. Ideally we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures.\n",
    "\n",
    "In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures.\n",
    "\n",
    "In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch Normalization as a tool to more efficiently optimize deep networks.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# As usual, a bit of setup\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train: ', (49000, 3, 32, 32))\n",
      "('y_train: ', (49000,))\n",
      "('X_val: ', (1000, 3, 32, 32))\n",
      "('y_val: ', (1000,))\n",
      "('X_test: ', (1000, 3, 32, 32))\n",
      "('y_test: ', (1000,))\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "  print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Affine layer: foward\n",
    "Open the file `cs231n/layers.py` and implement the `affine_forward` function.\n",
    "\n",
    "Once you are done you can test your implementaion by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.769849468192957e-10 True\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out), rel_error(out, correct_out) <= 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Affine layer: backward\n",
    "Now implement the `affine_backward` function and test your implementation using numeric gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  5.399100368651805e-11 True\n",
      "dw error:  9.904211865398145e-11 True\n",
      "db error:  2.4122867568119087e-11 True\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx), rel_error(dw_num, dw) <= 1e-10)\n",
    "print('dw error: ', rel_error(dw_num, dw), rel_error(dw_num, dw) <= 1e-10)\n",
    "print('db error: ', rel_error(db_num, db), rel_error(db_num, db) <= 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ReLU layer: forward\n",
    "Implement the forward pass for the ReLU activation function in the `relu_forward` function and test your implementation using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.999999798022158e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 5e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ReLU layer: backward\n",
    "Now implement the backward pass for the ReLU activation function in the `relu_backward` function and test your implementation using numeric gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.2756349136310288e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be around 3e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# \"Sandwich\" layers\n",
    "There are some common patterns of layers that are frequently used in neural nets. For example, affine layers are frequently followed by a ReLU nonlinearity. To make these common patterns easy, we define several convenience layers in the file `cs231n/layer_utils.py`.\n",
    "\n",
    "For now take a look at the `affine_relu_forward` and `affine_relu_backward` functions, and run the following to numerically gradient check the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward:\n",
      "dx error:  2.299579177309368e-11\n",
      "dw error:  8.162011105764925e-11\n",
      "db error:  7.826724021458994e-12\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "print('Testing affine_relu_forward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loss layers: Softmax and SVM\n",
    "You implemented these loss functions in the last assignment, so we'll give them to you for free here. You should still make sure you understand how they work by looking at the implementations in `cs231n/layers.py`.\n",
    "\n",
    "You can make sure that the implementations are correct by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.999602749096233\n",
      "dx error:  1.4021566006651672e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.302545844500738\n",
      "dx error:  9.384673161989355e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
    "print('Testing svm_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# l_data = []\n",
    "# for l in  range(self.num_layers):\n",
    "#     l_d = {}            \n",
    "#     l_d['scores_aff'], l_d['cache_aff'] = affine_forward(\n",
    "#         X if l==0 else l_data[l-1]['scores_act'],\n",
    "#         self.params['W'+str(l+1)], self.params['b'+str(l+1)])\n",
    "#     if l < (self.num_layers - 1):\n",
    "#        l_d['scores_act'], l_d['cache_act'] = \\\n",
    "#                 relu_forward(l_d['scores_aff'])\n",
    "#     l_data.append(l_d)\n",
    "# scores = l_data[self.num_layers-1]['scores_aff']  \n",
    "# #And then later in backprop somethin like this:\n",
    "# for l in  range(self.num_layers, 0, -1):\n",
    "#     dout, grads['W'+str(l)], grads['b'+str(l)] =\\\n",
    "#         affine_backward(dout, l_data[l-1]['cache_aff'])\n",
    "#     grads['W'+str(l)] += self.reg*self.params['W'+str(l)]\n",
    "#     if l > 1:\n",
    "#         dout = relu_backward(dout, l_data[l-2]['cache_act']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Two-layer network\n",
    "In the previous assignment you implemented a two-layer neural network in a single monolithic class. Now that you have implemented modular versions of the necessary layers, you will reimplement the two layer network using these modular implementations.\n",
    "\n",
    "Open the file `cs231n/classifiers/fc_net.py` and complete the implementation of the `TwoLayerNet` class. This class will serve as a model for the other networks you will implement in this assignment, so read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ...OK\n",
      "Testing test-time forward pass ...OK\n",
      "Testing training loss (no regularization) 3.47022435559539\n",
      "OK\n",
      "Testing training loss (regularization) 26.594842695238583 26.5948426952\n",
      "OK\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.83e-08\n",
      "W2 relative error: 3.12e-10\n",
      "b1 relative error: 9.83e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 2.53e-07\n",
      "W2 relative error: 7.98e-08\n",
      "b1 relative error: 1.56e-08\n",
      "b2 relative error: 7.76e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ...', end=\"\")\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "print(\"OK\")\n",
    "\n",
    "print('Testing test-time forward pass ...', end=\"\")\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "print(\"OK\")\n",
    "\n",
    "print('Testing training loss (no regularization)', end=\" \")\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "print(loss)\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "print(\"OK\")\n",
    "\n",
    "print('Testing training loss (regularization)', end=\" \")\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "print(loss, correct_loss)\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "print(\"OK\")\n",
    "\n",
    "for reg in [0.0, 0.7]:\n",
    "    print('Running numeric gradient check with reg = ', reg)\n",
    "    model.reg = reg\n",
    "    loss, grads = model.loss(X, y)\n",
    "#     print(grads)\n",
    "\n",
    "    for name in sorted(grads):\n",
    "        f = lambda _: model.loss(X, y)[0]\n",
    "        grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "        print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Solver\n",
    "In the previous assignment, the logic for training models was coupled to the models themselves. Following a more modular design, for this assignment we have split the logic for training models into a separate class.\n",
    "\n",
    "Open the file `cs231n/solver.py` and read through it to familiarize yourself with the API. After doing so, use a `Solver` instance to train a `TwoLayerNet` that achieves at least `50%` accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 2865) loss: 2.308532\n",
      "(Epoch 0 / 15) train acc: 0.186000; val_acc: 0.145000\n",
      "(Iteration 101 / 2865) loss: 1.678885\n",
      "(Epoch 1 / 15) train acc: 0.441000; val_acc: 0.404000\n",
      "(Iteration 201 / 2865) loss: 1.600792\n",
      "(Iteration 301 / 2865) loss: 1.634865\n",
      "(Epoch 2 / 15) train acc: 0.448000; val_acc: 0.447000\n",
      "(Iteration 401 / 2865) loss: 1.440880\n",
      "(Iteration 501 / 2865) loss: 1.550201\n",
      "(Epoch 3 / 15) train acc: 0.506000; val_acc: 0.462000\n",
      "(Iteration 601 / 2865) loss: 1.505938\n",
      "(Iteration 701 / 2865) loss: 1.503198\n",
      "(Epoch 4 / 15) train acc: 0.483000; val_acc: 0.471000\n",
      "(Iteration 801 / 2865) loss: 1.370941\n",
      "(Iteration 901 / 2865) loss: 1.399955\n",
      "(Epoch 5 / 15) train acc: 0.523000; val_acc: 0.485000\n",
      "(Iteration 1001 / 2865) loss: 1.373970\n",
      "(Iteration 1101 / 2865) loss: 1.377593\n",
      "(Epoch 6 / 15) train acc: 0.528000; val_acc: 0.503000\n",
      "(Iteration 1201 / 2865) loss: 1.414257\n",
      "(Iteration 1301 / 2865) loss: 1.387980\n",
      "(Epoch 7 / 15) train acc: 0.561000; val_acc: 0.506000\n",
      "(Iteration 1401 / 2865) loss: 1.350054\n",
      "(Iteration 1501 / 2865) loss: 1.328759\n",
      "(Epoch 8 / 15) train acc: 0.521000; val_acc: 0.499000\n",
      "(Iteration 1601 / 2865) loss: 1.354498\n",
      "(Iteration 1701 / 2865) loss: 1.307913\n",
      "(Epoch 9 / 15) train acc: 0.564000; val_acc: 0.501000\n",
      "(Iteration 1801 / 2865) loss: 1.354368\n",
      "(Iteration 1901 / 2865) loss: 1.220948\n",
      "(Epoch 10 / 15) train acc: 0.588000; val_acc: 0.500000\n",
      "(Iteration 2001 / 2865) loss: 1.200128\n",
      "(Iteration 2101 / 2865) loss: 1.164454\n",
      "(Epoch 11 / 15) train acc: 0.573000; val_acc: 0.499000\n",
      "(Iteration 2201 / 2865) loss: 1.332110\n",
      "(Epoch 12 / 15) train acc: 0.541000; val_acc: 0.498000\n",
      "(Iteration 2301 / 2865) loss: 1.354776\n",
      "(Iteration 2401 / 2865) loss: 1.216131\n",
      "(Epoch 13 / 15) train acc: 0.581000; val_acc: 0.519000\n",
      "(Iteration 2501 / 2865) loss: 1.235377\n",
      "(Iteration 2601 / 2865) loss: 1.335578\n",
      "(Epoch 14 / 15) train acc: 0.598000; val_acc: 0.508000\n",
      "(Iteration 2701 / 2865) loss: 1.250547\n",
      "(Iteration 2801 / 2865) loss: 1.273271\n",
      "(Epoch 15 / 15) train acc: 0.600000; val_acc: 0.514000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(hidden_dim=2**8)\n",
    "solver = None\n",
    "\n",
    "optim_config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "}\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "solver = Solver(model, data, \n",
    "                optim_config=optim_config, \n",
    "                print_every=100,\n",
    "                batch_size=256,\n",
    "               lr_decay=0.99,\n",
    "               num_epochs=15)\n",
    "solver.train()\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAALJCAYAAAD8s2GkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+8XutrLGvNXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4, 5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0] + [1,2,4] + [5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multilayer network\n",
    "Next you will implement a fully-connected network with an arbitrary number of hidden layers.\n",
    "\n",
    "Read through the `FullyConnectedNet` class in the file `cs231n/classifiers/fc_net.py`.\n",
    "\n",
    "Implement the initialization, the forward pass, and the backward pass. For the moment don't worry about implementing dropout or batch normalization; we will add those features soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initial loss and gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As a sanity check, run the following to check the initial loss and to gradient check the network both with and without regularization. Do the initial losses seem reasonable?\n",
    "\n",
    "For gradient checking, you should expect to see errors around 1e-6 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  2.3004790897684924\n",
      "W1 relative error: 1.4839894098713283e-07, True\n",
      "W2 relative error: 2.21204793107852e-05, False\n",
      "W3 relative error: 3.527252851540647e-07, True\n",
      "b1 relative error: 5.376386228531692e-09, True\n",
      "b2 relative error: 2.085654200257447e-09, True\n",
      "b3 relative error: 5.7957243458479405e-11, True\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  7.052114776533016\n",
      "W1 relative error: 1.0, False\n",
      "W2 relative error: 1.0, False\n",
      "W3 relative error: 1.0, False\n",
      "b1 relative error: 1.4752428222134868e-08, True\n",
      "b2 relative error: 1.7223750761525226e-09, True\n",
      "b3 relative error: 1.801765144951982e-10, True\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "    print('Running check with reg = ', reg)\n",
    "    model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "    loss, grads = model.loss(X, y)\n",
    "    print('Initial loss: ', loss)\n",
    "\n",
    "    for name in sorted(grads):\n",
    "        f = lambda _: model.loss(X, y)[0]\n",
    "        grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "        rel_err = rel_error(grad_num, grads[name])\n",
    "        print(f'{name} relative error: {rel_err}, {rel_err <= 1e-6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10 - 1, -1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As another sanity check, make sure you can overfit a small dataset of 50 images. First we will try a three-layer network with 100 units in each hidden layer. You will need to tweak the learning rate and initialization scale, but you should be able to overfit and achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2\n",
    "learning_rate = 1e-4\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now try to use a five-layer network with 100 units on each layer to overfit 50 training examples. Again you will have to adjust the learning rate and weight initialization, but you should be able to achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_scale = 1e-5\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Inline question: \n",
    "Did you notice anything about the comparative difficulty of training the three-layer net vs training the five layer net?\n",
    "\n",
    "# Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Update rules\n",
    "So far we have used vanilla stochastic gradient descent (SGD) as our update rule. More sophisticated update rules can make it easier to train deep networks. We will implement a few of the most commonly used update rules and compare them to vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SGD+Momentum\n",
    "Stochastic gradient descent with momentum is a widely used update rule that tends to make deep networks converge faster than vanilla stochstic gradient descent.\n",
    "\n",
    "Open the file `cs231n/optim.py` and read the documentation at the top of the file to make sure you understand the API. Implement the SGD+momentum update rule in the function `sgd_momentum` and run the following to check your implementation. You should see errors less than 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cs231n.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once you have done so, run the following to train a six-layer network with both SGD and SGD+momentum. You should see the SGD+momentum update rule converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-2,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# RMSProp and Adam\n",
    "RMSProp [1] and Adam [2] are update rules that set per-parameter learning rates by using a running average of the second moments of gradients.\n",
    "\n",
    "In the file `cs231n/optim.py`, implement the RMSProp update rule in the `rmsprop` function and implement the Adam update rule in the `adam` function, and check your implementations using the tests below.\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "from cs231n.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "from cs231n.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once you have debugged your RMSProp and Adam implementations, run the following to train a pair of deep networks using these new update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train a good model!\n",
    "Train the best fully-connected model that you can on CIFAR-10, storing your best model in the `best_model` variable. We require you to get at least 50% accuracy on the validation set using a fully-connected net.\n",
    "\n",
    "If you are careful it should be possible to get accuracies above 55%, but we don't require it for this part and won't assign extra credit for doing so. Later in the assignment we will ask you to train the best convolutional network that you can on CIFAR-10, and we would prefer that you spend your effort working on convolutional nets rather than fully-connected nets.\n",
    "\n",
    "You might find it useful to complete the `BatchNormalization.ipynb` and `Dropout.ipynb` notebooks before completing this part, since those techniques can help you train powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# batch normalization and dropout useful. Store your best model in the         #\n",
    "# best_model variable.                                                         #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test you model\n",
    "Run your best model on the validation and test sets. You should achieve above 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
